{
  "hash": "f08f163e8b3fb98a86da7bdd9a9ce22f",
  "result": {
    "markdown": "Loading of necessary libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressMessages(pacman::p_load(arrow, lubridate, tidyverse, tmap, sf))\n```\n:::\n\n---\ntitle: \"R for Geospatial Data Science\"\nformat:\n  html: \n    code-fold: true\n    code-summary: \"Show the code\"\nexecute:\n  eval: true\n  echo: true\n  warning: false\n  freeze: true\neditor: visual\n---\n\n\nImporting Grab-Posisi Dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- read_parquet(\"../../data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n```\n:::\n\n\nCode chunk to convert the data type of *pingtimestamp* from character to date-time. Replaces the characteristics of pingtimestamp into a date-time field.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf$pingtimestamp <- as_datetime(df$pingtimestamp)\n```\n:::\n\n\nExtract trip starting locations\n\n-   extracting trips' origin locations\n\n-   derive 3 new columns/variables for weekday, starting hour & day of the month\n\n-   name the output tibble.data.frame *origin_df*\n\n\n::: {.cell}\n\n```{.r .cell-code}\norigin_df <- df %>%\n  group_by(trj_id) %>%\n  arrange(pingtimestamp) %>%\n  filter(row_number()==1) %>%\n  mutate(weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n```\n:::\n\n\nwday 'label' converts 1,2,3,4,5,6,7 into Monday,Tuesday,Wednesday... wday 'abbr' converts Monday,Tuesday,Wednesday... into Mon,Tues,Wed... factor ensures the format 00:22:30 isn't read as 22h30mins but is forced to recognise 00 as the hour, 22 as minute, 30 as seconds.\n\nExtracting trip ending locations\n\n-   code that extracts trip's destination locations\n\n-   deriving weekday, ending hour & day of month columns\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndestination_df <- df %>%\n  group_by(trj_id) %>%\n  arrange(desc(pingtimestamp)) %>%\n  filter(row_number()==1) %>%\n  mutate(weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n```\n:::\n\n\n\\*Because we have multiple entries for same traj_id, we can sort the timings by descending order and see the latest one as the destination\n\nNow, we want to save this processed data to use in the future so we don't have to repeat the sorting process again and again.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(origin_df, \"../../data/rds/origin_df.rds\")\nwrite_rds(destination_df, \"../../data/rds/destination_df.rds\")\n```\n:::\n\n\nAnd next time, we can just import these new rds files (not excel as they're incapable of storing the data structures we use)\n\n\n::: {.cell}\n\n```{.r .cell-code}\norigin_df <- read_rds(\"../../data/rds/origin_df.rds\")\ndestination_df <- read_rds(\"../../data/rds/destination_df.rds\")\n```\n:::\n\n\nNow that we have these, we can add the line \"#\\| eval: false\" at the earlier code chunks where we imported the very big datas. In fact, once we have run the stuff above, we can just hide everything. We can also use \"#\\| echo: false\" to render it invisible.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}